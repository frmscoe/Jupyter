{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arango import ArangoClient\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pyodbc\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arango_server = os.environ[\"ARANGO_HOST\"]\n",
    "arango_db = os.environ[\"ARANGO_DATABASE\"]\n",
    "arango_password = os.environ[\"ARANGO_PASSWORD\"]\n",
    "arango_user = os.environ[\"ARANGO_USER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ArangoClient(hosts=arango_server)\n",
    "db = client.db(arango_db, username=arango_user, password=arango_password)\n",
    "cursor = db.aql.execute(\n",
    "    r\"LET DPTime = ( for doc in transactions return doc.report.metaData.prcgTmDP ) LET CRSPTime = (for doc in transactions return doc.report.metaData.prcgTmCRSP) LET RuleTime = (for doc in transactions FOR tp IN doc.report.tadpResult.channelResult[0].typologyResult FOR rule IN tp.ruleResults COLLECT prcgTm = rule.prcgTm RETURN  prcgTm ) LET TPTime = (for doc in transactions FOR tp IN doc.report.tadpResult.channelResult[0].typologyResult COLLECT prcgTm = tp.prcgTm RETURN  prcgTm ) LET CADPTime = (for doc in transactions return doc.report.tadpResult.channelResult[0].prcgTm) LET TADPTime = (for doc in transactions return   doc.report.tadpResult.prcgTm) LET E2ETimes = ( for doc in transactions COLLECT AGGREGATE mn= MIN(doc.report.timestamp), mx= MAX(doc.report.timestamp)  return {startTime: mn, endTime: mx, amount: LENGTH(transactions), elapsed: DATE_DIFF(mn, mx, 's'), ftps: LENGTH(transactions)/DATE_DIFF(mn, mx, 's')} ) LET DPStats = ( for doc in DPTime COLLECT AGGREGATE mn=MIN(doc), mx= MAX(doc), ave= AVERAGE(doc) return {mn:mn/1000000, mx:mx/1000000, ave:ave/1000000, mea:MEDIAN(DPTime)/1000000,ninety:PERCENTILE(DPTime, 90)/1000000,ninetynine:PERCENTILE(DPTime, 99)/1000000 } ) LET CRSPStats = ( for doc in CRSPTime COLLECT AGGREGATE mn= MIN(doc), mx= MAX(doc), ave= AVERAGE(doc)  return {mn:mn/1000000, mx:mx/1000000, ave:ave/1000000, mea:MEDIAN(CRSPTime)/1000000,ninety:PERCENTILE(CRSPTime, 90)/1000000,ninetynine:PERCENTILE(CRSPTime, 99)/1000000} ) LET RuleStats = ( for doc in RuleTime COLLECT AGGREGATE mn= MIN(doc), mx= MAX(doc), ave= AVERAGE(doc)  return {mn:mn/1000000, mx:mx/1000000, ave:ave/1000000, mea:MEDIAN(TPTime)/1000000,ninety:PERCENTILE(TPTime, 90)/1000000,ninetynine:PERCENTILE(TPTime, 99)/1000000} ) LET TPStats = ( for doc in TPTime COLLECT AGGREGATE mn= MIN(doc), mx= MAX(doc), ave= AVERAGE(doc)  return {mn:mn/1000000, mx:mx/1000000, ave:ave/1000000, mea:MEDIAN(TPTime)/1000000,ninety:PERCENTILE(TPTime, 90)/1000000,ninetynine:PERCENTILE(TPTime, 99)/1000000} ) LET CADPStats = ( for doc in CADPTime COLLECT AGGREGATE mn= MIN(doc), mx= MAX(doc), ave= AVERAGE(doc)  return {mn:mn/1000000, mx:mx/1000000, ave:ave/1000000, mea:MEDIAN(CADPTime)/1000000,ninety:PERCENTILE(CADPTime, 90)/1000000,ninetynine:PERCENTILE(CADPTime, 99)/1000000} ) LET TADPStats = ( for doc in TADPTime COLLECT AGGREGATE mn= MIN(doc), mx= MAX(doc), ave= AVERAGE(doc)  return {mn:mn/1000000, mx:mx/1000000, ave:ave/1000000, mea:MEDIAN(TADPTime)/1000000,ninety:PERCENTILE(TADPTime, 90)/1000000,ninetynine:PERCENTILE(TADPTime, 99)/1000000} ) RETURN {     startTime:E2ETimes[0].startTime,     endTime:E2ETimes[0].endTime,     amount:E2ETimes[0].amount,     elapsed:E2ETimes[0].elapsed,     ftps:E2ETimes[0].ftps,     DPStats,     CRSPStats,     RuleStats,     TPStats,     CADPStats,     TADPStats, DPTime, CRSPTime, RuleTime, TPTime, CADPTime, TADPTime }\"\n",
    ")\n",
    "documents = [document for document in cursor]\n",
    "\n",
    "\n",
    "run_details = documents[0]\n",
    "cursor = db.aql.execute(\n",
    "    r\"LET typologiesArr = ( FOR doc IN transactions FOR typologies IN doc.report.tadpResult.channelResult[0].typologyResult[*] RETURN typologies ) LET rulesArr = ( FOR typologies IN typologiesArr FOR rules IN typologies.ruleResults[*] RETURN rules ) LET ruleTimesById = ( FOR rules IN rulesArr COLLECT ruleId = rules.id INTO rules RETURN {rule: ruleId, prcgTm: {mn: MIN(rules[*].rules.prcgTm), mx: MAX(rules[*].rules.prcgTm), ave: AVERAGE(rules[*].rules.prcgTm), ninety: PERCENTILE(rules[*].rules.prcgTm,90), ninetyfive: PERCENTILE(rules[*].rules.prcgTm,95), ninetynine: PERCENTILE(rules[*].rules.prcgTm,99)}} ) LET RuleStatsMs = ( FOR obj in ruleTimesById RETURN {ruleId: obj.rule, mn: obj.prcgTm.mn/1000000, mx: obj.prcgTm.mx/1000000, ave: obj.prcgTm.ave/1000000, ninety: obj.prcgTm.ninety/1000000,ninetyfive: obj.prcgTm.ninetyfive/1000000,ninetynine: obj.prcgTm.ninetynine/1000000} ) RETURN RuleStatsMs\"\n",
    ")\n",
    "rules = documents = [document for document in cursor]\n",
    "\n",
    "processors = {\n",
    "    key: value[0] for (key, value) in run_details.items() if type(value) == list\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = run_details[\"startTime\"]\n",
    "end_time = run_details[\"endTime\"]\n",
    "dp_times = run_details[\"DPTime\"]\n",
    "crsp_times = run_details[\"CRSPTime\"]\n",
    "rules_times = run_details[\"RuleTime\"]\n",
    "tp_times = run_details[\"TPTime\"]\n",
    "cadp_times = run_details[\"CADPTime\"]\n",
    "tadp_times = run_details[\"TADPTime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert dataset to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(processors)\n",
    "df2 = pd.DataFrame(rules[0])\n",
    "df = df.drop(columns=[\"DPTime\",\"CRSPTime\",\"RuleTime\",\"TPTime\",\"CADPTime\",\"TADPTime\"])\n",
    "\n",
    "df2 = df2.set_index(\"ruleId\")\n",
    "\n",
    "#df_expanded = df2[\"prcgTm\"].apply(pd.Series)\n",
    "\n",
    "#update = df.drop(\"mx\")\n",
    "\n",
    "df_no_max = df2.drop(columns=[\"mx\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Rule Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"duration\")\n",
    "plt.title(\"Run summary\")\n",
    "plt.gca().xaxis.set_tick_params(rotation=0)\n",
    "\n",
    "df_no_max.plot(kind=\"bar\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"duration\")\n",
    "plt.title(\"Rule Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(data, processor):\n",
    "    plt.hist(data, bins=50, edgecolor=\"black\",alpha=0.6)\n",
    "    plt.title(f\"Frequency Distribution {processor}\")\n",
    "    plt.xlabel(\"duration\")\n",
    "    plt.ylabel(\"count\")\n",
    "    mean = np.mean(data)\n",
    "    total = sum(data)\n",
    "    plt.axvline(mean, linestyle=\"dashed\",color=\"red\",label=\"average\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return mean\n",
    "\n",
    "dp_mean = histogram(dp_times, \"DP\")\n",
    "crsp_mean = histogram(crsp_times, \"CRSP\")\n",
    "rules_mean = histogram(rules_times, \"Rules\")\n",
    "tp_mean = histogram(tp_times, \"TP\")\n",
    "cadp_mean = histogram(cadp_times, \"CADP\")\n",
    "tadp_mean = histogram(tadp_times, \"TADP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie([rules_mean, tp_mean, cadp_mean, tadp_mean, crsp_mean],labels=[\"Rules\", \"TP\", \"CADP\", \"TADP\", \"CRSP\"])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_dt = datetime.fromisoformat(start_time)\n",
    "end_time_dt = datetime.fromisoformat(end_time)\n",
    "time_difference = end_time_dt.timestamp() - start_time_dt.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = os.environ[\"SQL_HOST\"]\n",
    "database = os.environ[\"SQL_DB\"]\n",
    "username = os.environ[\"SQL_USER\"]\n",
    "password = os.environ[\"SQL_PASS\"]\n",
    "driver = os.environ[\"SQL_DRIVER\"]\n",
    "count = int(os.environ[\"PREVIOUS_BEST_COUNT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmnt = \"\"\"\n",
    "INSERT dbo.Run (\n",
    "crsp_avg,\n",
    "crsp_min,\n",
    "crsp_max,\n",
    "rules_avg,\n",
    "rules_min,\n",
    "rules_max,\n",
    "tadp_min,\n",
    "tadp_avg,\n",
    "tadp_max,\n",
    "cadp_min,\n",
    "cadp_max,\n",
    "cad_avg,\n",
    "dp_min,\n",
    "dp_avg,\n",
    "dp_max,\n",
    "transaction_count,\n",
    "start_time,\n",
    "end_time,\n",
    "avg_duration\n",
    ") OUTPUT INSERTED.id \n",
    "VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\"\n",
    "\n",
    "select_stmnt = f\"SELECT TOP {count} * FROM dbo.Run ORDER BY avg_duration;\"\n",
    "\n",
    "previous_runs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_datetimeoffset(dto_value):\n",
    "    # ref: https://github.com/mkleehammer/pyodbc/issues/134#issuecomment-281739794\n",
    "    tup = struct.unpack(\"<6hI2h\", dto_value)  # e.g., (2017, 3, 16, 10, 35, 18, 500000000, -6, 0)\n",
    "    return datetime(tup[0], tup[1], tup[2], tup[3], tup[4], tup[5], tup[6] // 1000,\n",
    "                    timezone(timedelta(hours=tup[7], minutes=tup[8])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyodbc.connect('DRIVER='+driver+';SERVER=tcp:'+server+';DATABASE='+database+';UID='+username+';PWD='+ password) as conn:\n",
    "    document_count = [document for document in db.aql.execute(\"RETURN LENGTH(transactions)\")]\n",
    "\n",
    "    with conn.cursor() as cursor:\n",
    "        conn.add_output_converter(-155, handle_datetimeoffset)\n",
    "        cursor.execute(select_stmnt)\n",
    "        previous_runs = pd.DataFrame.from_records(cursor.fetchall(), columns=[col[0] for col in cursor.description])\n",
    "        \n",
    "        cursor.execute(\n",
    "            insert_stmnt,\n",
    "            np.mean(crsp_times),\n",
    "            min(crsp_times),\n",
    "            max(crsp_times),\n",
    "            np.mean(rules_times),\n",
    "            min(rules_times),\n",
    "            max(rules_times),\n",
    "            min(tadp_times),\n",
    "            np.mean(tadp_times),\n",
    "            max(tadp_times),\n",
    "            min(cadp_times),\n",
    "            max(cadp_times),\n",
    "            np.mean(cadp_times),\n",
    "            min(dp_times),\n",
    "            np.mean(dp_times),\n",
    "            max(dp_times),\n",
    "            document_count[0],\n",
    "            start_time_dt,\n",
    "            end_time_dt,\n",
    "            time_difference / document_count[0]\n",
    "        )\n",
    "        resultId = cursor.fetchval()\n",
    "        print(f\"Run ID : {resultId} inserted\")\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_comparison(columns, previous_runs, current, processor):\n",
    "    columns.append(\"id\")\n",
    "    current_vis = previous_runs[columns]\n",
    "    current_vis = current_vis.set_index(\"id\")\n",
    "    current_vis = current_vis.astype(float)\n",
    "    df2 = {'current_avg': np.mean(current), 'current_min': min(current), 'current_max': max(current) }\n",
    "    current_vis = pd.concat([current_vis, pd.DataFrame([df2])], ignore_index=True)\n",
    "    current_vis.plot(kind=\"bar\")\n",
    "    plt.tight_layout()\n",
    "    plt.title(f\"{processor} vs previous best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_comparison([\"crsp_avg\", \"crsp_min\", \"crsp_max\"], previous_runs, crsp_times, \"CRSP\")\n",
    "vis_comparison([\"rules_avg\", \"rules_min\", \"rules_max\"], previous_runs, rules_times, \"Rules\")\n",
    "vis_comparison([\"tadp_avg\", \"tadp_min\", \"tadp_max\"], previous_runs, tadp_times, \"TADP\")\n",
    "vis_comparison([\"cad_avg\", \"cadp_min\", \"cadp_max\"], previous_runs, cadp_times, \"CADP\")\n",
    "vis_comparison([\"dp_avg\", \"dp_min\", \"dp_max\"], previous_runs, dp_times, \"DP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
